import streamlit as st
import os
import time
import tempfile
import numpy as np
from typing import Optional
import logging
import av
import queue

try:
    from streamlit_webrtc import (
        webrtc_streamer,
        WebRtcMode,
        RTCConfiguration,
        AudioProcessorBase,
        MediaStreamConstraints,
        WebRtcStreamerContext,
    )
    WEBRTC_AVAILABLE = True
except ImportError:
    WEBRTC_AVAILABLE = False
    logging.warning("streamlit-webrtc –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –∑–∞–ø–∏—Å–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")

class AudioRecorder:
    def __init__(self, use_fallback=False):
        self.use_fallback = use_fallback
        self.audio_data = None
        self.recording_state = {"recording": False, "finished": False}
    
    def use_webrtc_recorder(self):
        """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç streamlit-webrtc –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ"""
        if not WEBRTC_AVAILABLE:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å streamlit-webrtc. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ —Å –ø–æ–º–æ—â—å—é: pip install streamlit-webrtc")
            return None
        
        st.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ WebRTC")
        
        class AudioProcessor(AudioProcessorBase):
            def __init__(self):
                self.audio_buffer = []
                self.sample_rate = 16000
                self.audio_queue = queue.Queue()
                self.recording = False
                
            def recv(self, frame):
                """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞—É–¥–∏–æ-—Ñ—Ä–µ–π–º–∞ –æ—Ç WebRTC"""
                if self.recording:
                    sound = frame.to_ndarray()
                    sound = sound.reshape(-1)
                    self.audio_buffer.extend(sound.tolist())
                return frame
            
            def get_audio_data(self):
                """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –∞—É–¥–∏–æ-–¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –±–∞–π—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ WAV"""
                if not self.audio_buffer:
                    return None
                
                # –°–æ–∑–¥–∞–Ω–∏–µ WAV-—Ñ–∞–π–ª–∞ –∏–∑ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                import wave
                import io
                
                audio_bytes = io.BytesIO()
                with wave.open(audio_bytes, 'wb') as wav_file:
                    wav_file.setnchannels(1)  # –ú–æ–Ω–æ
                    wav_file.setsampwidth(2)  # 16-bit
                    wav_file.setframerate(self.sample_rate)
                    audio_array = np.array(self.audio_buffer, dtype=np.int16)
                    wav_file.writeframes(audio_array.tobytes())
                
                return audio_bytes.getvalue()
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ICE-—Å–µ—Ä–≤–µ—Ä–æ–≤ –¥–ª—è WebRTC
        rtc_configuration = RTCConfiguration(
            {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
        )
        
        # –°–æ–∑–¥–∞–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ WebRTC —Å—Ç—Ä–∏–º–µ—Ä–∞
            audio_processor = AudioProcessor()
            webrtc_ctx = webrtc_streamer(
                key="audio-recorder",
                mode=WebRtcMode.SENDRECV,
                rtc_configuration=rtc_configuration,
                media_stream_constraints={"video": False, "audio": True},
                audio_processor_factory=lambda: audio_processor,
                async_processing=True,
            )
        
        with col2:
            # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å—å—é
            if webrtc_ctx.state.playing:
                if st.button("üî¥ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å", disabled=audio_processor.recording):
                    audio_processor.recording = True
                    audio_processor.audio_buffer = []  # –û—á–∏—Å—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞
                    st.session_state['webrtc_recording'] = True
                
                if st.button("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å", disabled=not audio_processor.recording):
                    audio_processor.recording = False
                    st.session_state['webrtc_recording'] = False
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ
                    audio_data = audio_processor.get_audio_data()
                    if audio_data:
                        st.session_state['webrtc_audio_data'] = audio_data
                        st.success("–ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω–æ!")
                        st.audio(audio_data, format="audio/wav")
                        return audio_data
                    else:
                        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–ø–∏—Å–∏
                if 'webrtc_recording' in st.session_state and st.session_state['webrtc_recording']:
                    st.markdown("#### üî¥ –ò–¥–µ—Ç –∑–∞–ø–∏—Å—å...")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞–Ω–µ–µ –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
        if 'webrtc_audio_data' in st.session_state:
            return st.session_state['webrtc_audio_data']
        
        return None
    
    def use_standard_recorder(self):
        """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π st.audio_input"""
        audio_data = st.audio_input("–ù–∞–∂–º–∏—Ç–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ")
        return audio_data
    
    def record_audio(self) -> Optional[bytes]:
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –∫–∞–∫ bytes"""
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–Ω–æ–µ
        if not self.use_fallback:
            audio_data = self.use_standard_recorder()
            if audio_data is not None:
                return audio_data
        
        # –ï—Å–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–ª–∏ —É–∫–∞–∑–∞–Ω fallback, –∏—Å–ø–æ–ª—å–∑—É–µ–º WebRTC
        return self.use_webrtc_recorder()
    
    def render_audio_recorder(self, title="–ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ"):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        st.subheader(title)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–µ—Ç–æ–¥–∞ –∑–∞–ø–∏—Å–∏
        record_method = st.radio(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ:",
            ["–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)", "–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π (–¥–ª—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤)"],
            index=1 if self.use_fallback else 0,
        )
        
        self.use_fallback = record_method == "–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π (–¥–ª—è —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤)"
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –∑–∞–ø–∏—Å–∏
        audio_data = None
        if self.use_fallback:
            audio_data = self.use_webrtc_recorder()
        else:
            audio_data = self.use_standard_recorder()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        return audio_data

def create_audio_recorder(use_fallback=False):
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –∞—É–¥–∏–æ-—Ä–µ–∫–æ—Ä–¥–µ—Ä–∞"""
    return AudioRecorder(use_fallback=use_fallback) 